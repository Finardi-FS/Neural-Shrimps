{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import h5py\n",
    "from datetime import datetime\n",
    "import jupyprint.jupyprint as jp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../00_Classes')\n",
    "import CNN_Class\n",
    "\n",
    "CNN = CNN_Class.MyCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Mnist Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n",
      "Epoch: 10\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "images = CNN.load_MNIST_images('MNIST_data/t10k-images-idx3-ubyte.gz')\n",
    "labels = CNN.load_MNIST_labels('MNIST_data/t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "\n",
    "CNN.Rng(1)\t\t\t\t\t\t\t\t\t\t\t\t# imposto il seme per la generazione di numeri casuali sia per np.random che per random.\n",
    "\n",
    "W1 = 1e-2 * np.random.randn(20, 9, 9)\t\t\t\t\t\t\t\t\t\n",
    "W5 = (2 * np.random.rand(100, 2000) - 1) * np.sqrt(6) / np.sqrt(360 + 2000)\n",
    "Wo = (2 * np.random.rand(10, 100) - 1) * np.sqrt(6) / np.sqrt(10 + 100)\n",
    "\n",
    "X = images[:7000 ,: ,:]\n",
    "D = labels[:7000]\n",
    "\n",
    "# Training\n",
    "for epoch in range(10):\n",
    "\tprint(\"Epoch:\", epoch + 1)\n",
    "\tW1, W5, Wo = CNN.SGD_MnistConv(W1, W5, Wo, X, D, 0.001, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights\n",
    "with h5py.File('MnistConv.h5', 'w') as hf:\n",
    "\thf.create_dataset('W1', data=W1)\n",
    "\thf.create_dataset('W5', data=W5)\n",
    "\thf.create_dataset('Wo', data=Wo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 100%\n",
      "Accuracy is 0.473158\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "# X_test = images[:7000, :, :]\n",
    "# D_test = labels[:7000]\n",
    "X_test = images[7001:10000, :, :]\n",
    "D_test = labels[7001:10000]\n",
    "acc = 0\n",
    "N = len(D_test)\n",
    "\n",
    "for k in range(N):\n",
    "\tprint(f'\\rSample: {int((k + 1)/len(D_test)*100)}%', end='')\n",
    "\tsys.stdout.flush()\n",
    "\tx = X_test[k, :, :]\n",
    "\ty1 = CNN.Conv(x, W1)\n",
    "\ty2 = CNN.ReLU(y1)\n",
    "\ty3 = CNN.Pool(y2)\n",
    "\ty4 = y3.flatten()\n",
    "\tv5 = W5 @ y4\n",
    "\ty5 = CNN.ReLU(v5)\n",
    "\tv = Wo @ y5\n",
    "\ty = CNN.Softmax(v)\n",
    "\t\n",
    "\ti = np.argmax(y)\n",
    "\tif i == D_test[k]:\n",
    "\t\tacc += 1\n",
    "print()\n",
    "acc = acc / N\n",
    "print('Accuracy is %f' % acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN-venv",
   "language": "python",
   "name": "nn-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
