{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - Exercise 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    python -m venv ML-venv\n",
    "    QTLab-venv\\Scripts\\activate\n",
    "    python.exe -m pip install --upgrade pip\n",
    "    pip install matplotlib numpy ipykernel jupyter\n",
    "    ipython kernel install --name \"ML-venv\" --user\n",
    "    https://queirozf.com/entries/jupyter-kernels-how-to-add-change-remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funzioni\n",
    "$w'_i=w_i-\\text{LR}\\cdot\\frac{\\partial f_{cost}}{\\partial w_i}=w_i-\\text{LR}\\cdot\\frac{\\partial f_{cost}}{\\partial P}\\cdot\\frac{\\partial P}{\\partial t}\\cdot\\frac{\\partial t}{\\partial w_i}$ \n",
    "\n",
    "Con:\n",
    "- $w_i$: Peso della i-esima feature\n",
    "- $\\text{LR}$: Learning Rate\n",
    "- $f_{cost}$: Funzione di costo\n",
    "- $t$: Combinazione lineare delle feature pesate \n",
    "- $P$: Combinazione lineare normalizzata con la sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "def SGD_method(weight, f_input, correct_output):\n",
    "# weight:           vettore dei pesi relativi alle feature\n",
    "# f_input:          dataset contenente i valori delle feature per ciascun campione\n",
    "# correct_output:   vettore dei valori attesi per ciascun campione\n",
    "\n",
    "    LR = 0.9    # learning rate\n",
    "    N  = 4      # numero di epoche\n",
    "\n",
    "    for k in range(N):                                              # ciclo sui campioni\n",
    "        expected = correct_output[k]                                # prendo il valore atteso del k-esimo campione\n",
    "        lin_comb = weight @ f_input[k, :]                           # combinazione lineare delle feature pesate per il k-esimo campione\n",
    "        predicted = Sigmoid(lin_comb)                               # normalizzazione della comb. lin. attraverso la funzione Sigmoid         \n",
    "        cost_function_der = 2 * (predicted - expected)              # derivata della funzione di costo (rispetto alla variabile predicted) \n",
    "                                                                    # relativa alla metrica Squared Error Cost                         \n",
    "        sigmoid_der = predicted * (1 - predicted)                   # derivata del sigmoid rispetto a lin_comb\n",
    "        lc_der = f_input[k, :]                                      # vettore di derivate di lin_comb rispetto ai pesi w (e al bias b)\n",
    "\n",
    "        dWeight = LR * cost_function_der * sigmoid_der * lc_der     # termine differenziale di aggiustamento per ricavare i nuovi pesi\n",
    "        weight -= dWeight                                           # correzione dei pesi\n",
    "\n",
    "    return weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
