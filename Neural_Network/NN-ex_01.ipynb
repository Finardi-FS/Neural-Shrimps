{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - Exercise 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    python -m venv NN-venv\n",
    "    NN-venv\\Scripts\\activate\n",
    "    python.exe -m pip install --upgrade pip\n",
    "    pip install matplotlib numpy ipykernel jupyter\n",
    "    ipython kernel install --name \"NN-venv\" --user\n",
    "    https://queirozf.com/entries/jupyter-kernels-how-to-add-change-remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jupyprint.jupyprint as jp\n",
    "from scipy.io import loadmat\n",
    "# from graphviz import Digraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of flags to enable or disable parts of codes\n",
    "\n",
    "flag_trained_network    = True\n",
    "flag_my_init_pars       = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Weights"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.56557803 -0.20886763 -4.57514966]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Correct Outputs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Feature Inputs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [1 1 1]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Epoch"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Trained Network\n",
    "\n",
    "if flag_trained_network:\n",
    "    file_name = 'Trained_Network.mat'\n",
    "    mat_data = loadmat(file_name)\n",
    "\n",
    "    weights          = mat_data['Weight']\n",
    "    correct_outputs  = mat_data['correct_Output']\n",
    "    epoch            = mat_data['epoch'][0][0]\n",
    "    feature_inputs   = mat_data['input']\n",
    "\n",
    "    jp('### Weights')\n",
    "    print(weights)\n",
    "    jp('### Correct Outputs')\n",
    "    print(correct_outputs)\n",
    "    jp('### Feature Inputs')\n",
    "    print(feature_inputs)\n",
    "    jp('### Epoch')\n",
    "    print(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Function\n",
    "\n",
    "$\\text{Sigmoid}(x)=\\dfrac{1}{1+e^{-x}}$\n",
    "\n",
    "$\\dfrac{\\partial}{\\partial x}\\left[\\text{Sigmoid}(x)\\right]=\\dfrac{e^{-x}}{(1+e^{-x})^2}=\\dfrac{1}{1+e^{-x}}\\cdot\\left(1-\\dfrac{1}{1+e^{-x}}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid Function\n",
    "\n",
    "def Sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent\n",
    "$w'_i=w_i-\\text{LR}\\cdot\\frac{\\partial f_{cost}}{\\partial w_i}=w_i-\\text{LR}\\cdot\\frac{\\partial f_{cost}}{\\partial P}\\cdot\\frac{\\partial P}{\\partial t}\\cdot\\frac{\\partial t}{\\partial w_i}$ \n",
    "\n",
    "Con:\n",
    "- $w_i$: Peso della i-esima feature\n",
    "- $\\text{LR}$: Learning Rate\n",
    "- $f_{cost}$: Funzione di costo\n",
    "- $t$: Combinazione lineare delle feature pesate \n",
    "- $P$: Combinazione lineare normalizzata con la sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "def SGD_method(weight, dataset, correct_output):\n",
    "# weight:           vettore dei pesi relativi alle feature\n",
    "# f_input:          dataset contenente i valori delle feature per ciascun campione\n",
    "# correct_output:   vettore dei valori attesi per ciascun campione\n",
    "\n",
    "    LR = 0.9            # learning rate\n",
    "\n",
    "    for k in range(len(weight)): \n",
    "        \n",
    "        sample = dataset[k, :]                                      # ciclo sui campioni\n",
    "        expected = correct_output[k]                                # prendo il valore atteso del k-esimo campione\n",
    "        lin_comb = weight @ sample                                  # combinazione lineare delle feature pesate per il k-esimo campione\n",
    "        predicted = Sigmoid(lin_comb)                               # normalizzazione della comb. lin. attraverso la funzione Sigmoid         \n",
    "        cost_function_der = 2 * (predicted - expected)              # derivata della funzione di costo (rispetto alla variabile predicted) \n",
    "                                                                    # relativa alla metrica Squared Error Cost                         \n",
    "        sigmoid_der = predicted * (1 - predicted)                   # derivata del sigmoid rispetto a lin_comb\n",
    "        lc_der = sample                                             # vettore di derivate di lin_comb rispetto ai pesi w (e al bias b)\n",
    "\n",
    "        dWeight = LR * cost_function_der * sigmoid_der * lc_der     # termine differenziale di aggiustamento per ricavare i nuovi pesi\n",
    "        weight -= dWeight                                           # correzione dei pesi\n",
    "\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial parameters\n",
    "\n",
    "if flag_my_init_pars:\n",
    "    weights          = None\n",
    "    correct_outputs  = np.array([[0, 0, 1, 1]]).T\n",
    "    epoch            = None\n",
    "    feature_inputs   = np.array([[0, 0, 1],\n",
    "                                 [0, 1, 1],\n",
    "                                 [1, 0, 1],\n",
    "                                 [1, 1, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN-venv",
   "language": "python",
   "name": "nn-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
